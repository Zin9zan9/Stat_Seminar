{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simulationen für MCAR mit den Top5 erklärenden Variablen (standardisiert)\n",
    "In dem Notebook 'ols_prep' wird eine lineare Regression des Laptop-Preises auf alle Exogenen durchgeführt.\n",
    "Anschließend werden alle Betas standardisiert und absteigend nach ihrer (absoluten) Größe sortiert. Daraus resultiert der Erklärungsgehalt der verschiedenen Exogenen. Wir nehmen die fünf Exogenen, die den größten Erklärungsgehalt haben und standardisieren sie. Sie dienen als Grundlage für die Simulationen in diesem Notebook. \n",
    "Es werden MCAR-Simulationen mit k=1000 durchgeführt, wobei jeweils nur die Top5 standardisierten Exogenen verwendet werden.\n",
    "Es wird kein Jitter hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "rng = np.random.RandomState(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung von DataFrames und Data Cleaning\n",
    "df = pd.read_csv('../Laptop-Preise.csv', sep=';', decimal=',')\n",
    "df = df[df.extern_Schnittstellen != 2300] # Ausreißer löschen\n",
    "df = df.reset_index(drop=True) # Reset Index\n",
    "\n",
    "# Nur die 5 Spalten auswählen, die auch den größten Erklärungsgehalt haben\n",
    "selected_columns = ['Preis', 'Akku_Kapazitaet', 'Arbeitsspeicher', 'Kerne', 'Marke_Apple', 'Betriebssystem_Windows']\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "df_noPrice = df.drop('Preis', axis=1)\n",
    "imputed_simul_knn = pd.DataFrame(columns=['Mean KNN_1', 'MSE KNN_1', 'SE KNN_1', 'Alpha KNN_1', 'Mean KNN_3', 'MSE KNN_3', 'SE KNN_3', 'Alpha KNN_3', 'Mean KNN_5', 'MSE KNN_5', 'SE KNN_5', 'Alpha KNN_5'])\n",
    "imputed_stats_knn = pd.DataFrame(columns=['Mean KNN_1', 'MSE KNN_1', 'SE KNN_1', 'Alpha KNN_1', 'Mean KNN_3', 'MSE KNN_3', 'SE KNN_3', 'Alpha KNN_3', 'Mean KNN_5', 'MSE KNN_5', 'SE KNN_5', 'Alpha KNN_5'], index = np.arange(0.1, 1, 0.1))\n",
    "\n",
    "imputed_simul_ols = pd.DataFrame(columns=['Mean', 'MSE OLS', 'SE OLS', 'Alpha OLS'])\n",
    "imputed_stats_ols = pd.DataFrame(columns=['Mean', 'MSE OLS', 'SE OLS', 'Alpha OLS'], index = np.arange(0.1, 1, 0.1))\n",
    "\n",
    "no_imputation = pd.DataFrame(columns = ['SE', 'Alpha'])\n",
    "\n",
    "# Skalierung (Standardisierung) von df_noPrice\n",
    "col_names = df_noPrice.columns\n",
    "scaler = StandardScaler().fit(df_noPrice.values)\n",
    "df_noPrice = scaler.transform(df_noPrice.values)\n",
    "df_noPrice = pd.DataFrame(df_noPrice, columns=col_names)\n",
    "\n",
    "# Skalierung (Standardisierung) von df mit Preis (Preis ist unverändert)\n",
    "df_std = df_noPrice.copy()\n",
    "df_std.insert(0, 'Preis', df['Preis'])\n",
    "\n",
    "# Wahrer Mittelwert:\n",
    "true_mean = df['Preis'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_mean(values):\n",
    "    return 1 if (true_mean > (np.mean(values) - 1.95996 * stats.sem(values))) and (true_mean < (np.mean(values) + 1.95996 * stats.sem(values))) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Preis   R-squared:                       0.765\n",
      "Model:                            OLS   Adj. R-squared:                  0.764\n",
      "Method:                 Least Squares   F-statistic:                     671.7\n",
      "Date:                Sat, 30 Mar 2024   Prob (F-statistic):          1.96e-321\n",
      "Time:                        12:19:10   Log-Likelihood:                -7590.4\n",
      "No. Observations:                1038   AIC:                         1.519e+04\n",
      "Df Residuals:                    1032   BIC:                         1.522e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                   1333.9633     11.290    118.149      0.000    1311.808    1356.118\n",
      "Akku_Kapazitaet          271.4884     15.663     17.333      0.000     240.754     302.223\n",
      "Arbeitsspeicher          328.6144     14.574     22.548      0.000     300.016     357.213\n",
      "Kerne                     95.1929     16.210      5.873      0.000      63.385     127.001\n",
      "Marke_Apple              185.5750     15.455     12.007      0.000     155.247     215.903\n",
      "Betriebssystem_Windows    93.8580     14.741      6.367      0.000      64.933     122.783\n",
      "==============================================================================\n",
      "Omnibus:                      134.748   Durbin-Watson:                   1.725\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              205.396\n",
      "Skew:                           0.896   Prob(JB):                     2.51e-45\n",
      "Kurtosis:                       4.239   Cond. No.                         2.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# OLS Model \n",
    "# fitting the model \n",
    "# df_noPrice ist bereits standardisiert\n",
    "model = sm.OLS(df['Preis'], sm.add_constant(df_noPrice)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  Akku_Kapazitaet &  Arbeitsspeicher &  Kerne &  Marke_Apple &  Betriebssystem_Windows \\\\\n",
      "\\midrule\n",
      "Akku_Kapazitaet        &             1.00 &             0.52 &   0.66 &         0.26 &                   -0.11 \\\\\n",
      "Arbeitsspeicher        &             0.52 &             1.00 &   0.58 &         0.29 &                   -0.10 \\\\\n",
      "Kerne                  &             0.66 &             0.58 &   1.00 &         0.16 &                   -0.07 \\\\\n",
      "Marke_Apple            &             0.26 &             0.29 &   0.16 &         1.00 &                   -0.64 \\\\\n",
      "Betriebssystem_Windows &            -0.11 &            -0.10 &  -0.07 &        -0.64 &                    1.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckopp\\AppData\\Local\\Temp\\ipykernel_18496\\1598365797.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_noPrice.corr().to_latex(escape=False, float_format=\"%.2f\"))\n"
     ]
    }
   ],
   "source": [
    "print(df_noPrice.corr().to_latex(escape=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_ran(df_exog, labels, chance):\n",
    "    rand_array = np.random.rand(df_exog.shape[0])\n",
    "    delete_entries = rand_array < chance\n",
    "    keep_entries = rand_array >= chance\n",
    "    \n",
    "    return [df_exog[delete_entries], labels[delete_entries], df_exog[keep_entries], labels[keep_entries]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_ols(test_values, test_labels, train_values, train_labels):\n",
    "    \n",
    "    # OLS Model\n",
    "    # fitting the model \n",
    "    model = sm.OLS(train_labels, sm.add_constant(train_values)).fit() \n",
    "    imputed_values = model.predict(exog = sm.add_constant(test_values, has_constant='add')).tolist()\n",
    "    return [np.mean(list(train_labels) + imputed_values), np.mean((imputed_values-test_labels)**2), stats.sem(list(train_labels) + imputed_values), contains_mean(list(train_labels) + imputed_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_knn(test_values, test_labels, train_values, train_labels):\n",
    "    \n",
    "    tree = KDTree(train_values.values, leaf_size=5)\n",
    "\n",
    "    imputed_values_knn_1 = []\n",
    "    imputed_values_knn_3 = []\n",
    "    imputed_values_knn_5 = []\n",
    "\n",
    "    for index, entry in enumerate(test_values.values):\n",
    " \n",
    "        dist, ind = tree.query([entry], k=5)\n",
    "        ind = ind[0]\n",
    "\n",
    "        current_impute_knn_1 = np.mean(train_labels.values[ind][0])\n",
    "        current_impute_knn_3 = np.mean(train_labels.values[ind][:3])\n",
    "        current_impute_knn_5 = np.mean(train_labels.values[ind])\n",
    "\n",
    "        imputed_values_knn_1.append(current_impute_knn_1)\n",
    "        imputed_values_knn_3.append(current_impute_knn_3)\n",
    "        imputed_values_knn_5.append(current_impute_knn_5)\n",
    "\n",
    "    mean_knn_1 = np.mean(list(train_labels.values)+imputed_values_knn_1)\n",
    "    mean_knn_3 = np.mean(list(train_labels.values)+imputed_values_knn_3)\n",
    "    mean_knn_5 = np.mean(list(train_labels.values)+imputed_values_knn_5)\n",
    "\n",
    "    mse_knn_1 = np.mean((test_labels.values - imputed_values_knn_1)**2)\n",
    "    mse_knn_3 = np.mean((test_labels.values - imputed_values_knn_3)**2)\n",
    "    mse_knn_5 = np.mean((test_labels.values - imputed_values_knn_5)**2)\n",
    "\n",
    "    sem_knn_1 = stats.sem(list(train_labels.values)+imputed_values_knn_1)\n",
    "    sem_knn_3 = stats.sem(list(train_labels.values)+imputed_values_knn_3)\n",
    "    sem_knn_5 = stats.sem(list(train_labels.values)+imputed_values_knn_5)\n",
    "\n",
    "    alpha_knn_1 = contains_mean(list(train_labels.values)+imputed_values_knn_1)\n",
    "    alpha_knn_3 = contains_mean(list(train_labels.values)+imputed_values_knn_3)\n",
    "    alpha_knn_5 = contains_mean(list(train_labels.values)+imputed_values_knn_5)\n",
    "\n",
    "\n",
    "    return [mean_knn_1, mse_knn_1, sem_knn_1, alpha_knn_1, mean_knn_3, mse_knn_3, sem_knn_3, alpha_knn_3, mean_knn_5, mse_knn_5, sem_knn_5, alpha_knn_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 47.74it/s]\n",
      "100%|██████████| 1000/1000 [00:35<00:00, 27.91it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.46it/s]\n",
      "100%|██████████| 1000/1000 [01:03<00:00, 15.84it/s]\n",
      "100%|██████████| 1000/1000 [01:11<00:00, 14.08it/s]\n",
      "100%|██████████| 1000/1000 [01:17<00:00, 12.83it/s]\n",
      "100%|██████████| 1000/1000 [01:44<00:00,  9.53it/s]\n",
      "100%|██████████| 1000/1000 [01:55<00:00,  8.66it/s]\n",
      "100%|██████████| 1000/1000 [02:05<00:00,  7.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean KNN_1</th>\n",
       "      <th>MSE KNN_1</th>\n",
       "      <th>SE KNN_1</th>\n",
       "      <th>Alpha KNN_1</th>\n",
       "      <th>Mean KNN_3</th>\n",
       "      <th>MSE KNN_3</th>\n",
       "      <th>SE KNN_3</th>\n",
       "      <th>Alpha KNN_3</th>\n",
       "      <th>Mean KNN_5</th>\n",
       "      <th>MSE KNN_5</th>\n",
       "      <th>SE KNN_5</th>\n",
       "      <th>Alpha KNN_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1328.904121</td>\n",
       "      <td>144725.958523</td>\n",
       "      <td>23.314619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1330.512545</td>\n",
       "      <td>101799.431127</td>\n",
       "      <td>23.152998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1329.303256</td>\n",
       "      <td>101453.57621</td>\n",
       "      <td>23.130188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>1324.53373</td>\n",
       "      <td>148937.277874</td>\n",
       "      <td>23.359979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1327.898625</td>\n",
       "      <td>102555.773564</td>\n",
       "      <td>23.040364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1325.812603</td>\n",
       "      <td>101634.175516</td>\n",
       "      <td>23.001157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>1320.614481</td>\n",
       "      <td>150109.559518</td>\n",
       "      <td>23.373354</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1325.34474</td>\n",
       "      <td>102773.396164</td>\n",
       "      <td>22.911847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1321.947291</td>\n",
       "      <td>102668.821334</td>\n",
       "      <td>22.830639</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>1318.347609</td>\n",
       "      <td>150563.493549</td>\n",
       "      <td>23.365886</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1323.373148</td>\n",
       "      <td>104724.100857</td>\n",
       "      <td>22.775051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1319.336405</td>\n",
       "      <td>104091.246262</td>\n",
       "      <td>22.640742</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>1317.057001</td>\n",
       "      <td>150984.801671</td>\n",
       "      <td>23.357222</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1320.675393</td>\n",
       "      <td>107335.591272</td>\n",
       "      <td>22.60923</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1316.602002</td>\n",
       "      <td>106478.690737</td>\n",
       "      <td>22.425439</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>1315.224536</td>\n",
       "      <td>153330.752355</td>\n",
       "      <td>23.265215</td>\n",
       "      <td>0.909</td>\n",
       "      <td>1318.781037</td>\n",
       "      <td>111619.441456</td>\n",
       "      <td>22.409946</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1316.443462</td>\n",
       "      <td>110837.241505</td>\n",
       "      <td>22.194793</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>1315.451176</td>\n",
       "      <td>157534.744797</td>\n",
       "      <td>23.16521</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1318.109198</td>\n",
       "      <td>118288.138527</td>\n",
       "      <td>22.171094</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1319.605801</td>\n",
       "      <td>118169.839346</td>\n",
       "      <td>21.946924</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>1316.350486</td>\n",
       "      <td>165664.521796</td>\n",
       "      <td>23.057403</td>\n",
       "      <td>0.805</td>\n",
       "      <td>1321.411444</td>\n",
       "      <td>129788.427576</td>\n",
       "      <td>21.902743</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1327.002092</td>\n",
       "      <td>131910.950046</td>\n",
       "      <td>21.495037</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>1319.637508</td>\n",
       "      <td>198371.575576</td>\n",
       "      <td>22.949349</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1323.164278</td>\n",
       "      <td>163663.523037</td>\n",
       "      <td>21.115205</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1315.873256</td>\n",
       "      <td>168944.307902</td>\n",
       "      <td>19.799125</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mean KNN_1      MSE KNN_1   SE KNN_1 Alpha KNN_1   Mean KNN_3  \\\n",
       "0.1  1328.904121  144725.958523  23.314619         1.0  1330.512545   \n",
       "0.2   1324.53373  148937.277874  23.359979         1.0  1327.898625   \n",
       "0.3  1320.614481  150109.559518  23.373354       0.996   1325.34474   \n",
       "0.4  1318.347609  150563.493549  23.365886       0.995  1323.373148   \n",
       "0.5  1317.057001  150984.801671  23.357222       0.962  1320.675393   \n",
       "0.6  1315.224536  153330.752355  23.265215       0.909  1318.781037   \n",
       "0.7  1315.451176  157534.744797   23.16521       0.875  1318.109198   \n",
       "0.8  1316.350486  165664.521796  23.057403       0.805  1321.411444   \n",
       "0.9  1319.637508  198371.575576  22.949349       0.665  1323.164278   \n",
       "\n",
       "         MSE KNN_3   SE KNN_3 Alpha KNN_3   Mean KNN_5      MSE KNN_5  \\\n",
       "0.1  101799.431127  23.152998         1.0  1329.303256   101453.57621   \n",
       "0.2  102555.773564  23.040364         1.0  1325.812603  101634.175516   \n",
       "0.3  102773.396164  22.911847         1.0  1321.947291  102668.821334   \n",
       "0.4  104724.100857  22.775051         1.0  1319.336405  104091.246262   \n",
       "0.5  107335.591272   22.60923       0.994  1316.602002  106478.690737   \n",
       "0.6  111619.441456  22.409946       0.977  1316.443462  110837.241505   \n",
       "0.7  118288.138527  22.171094       0.936  1319.605801  118169.839346   \n",
       "0.8  129788.427576  21.902743       0.881  1327.002092  131910.950046   \n",
       "0.9  163663.523037  21.115205       0.691  1315.873256  168944.307902   \n",
       "\n",
       "      SE KNN_5 Alpha KNN_5  \n",
       "0.1  23.130188         1.0  \n",
       "0.2  23.001157         1.0  \n",
       "0.3  22.830639         1.0  \n",
       "0.4  22.640742       0.998  \n",
       "0.5  22.425439       0.993  \n",
       "0.6  22.194793       0.971  \n",
       "0.7  21.946924       0.944  \n",
       "0.8  21.495037       0.902  \n",
       "0.9  19.799125       0.599  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simul_knn():\n",
    "    for c in np.arange(0.1, 1, 0.1):\n",
    "\n",
    "        imputed_simul_knn = pd.DataFrame(columns=['Mean KNN_1', 'MSE KNN_1', 'SE KNN_1', 'Alpha KNN_1', 'Mean KNN_3', 'MSE KNN_3', 'SE KNN_3', 'Alpha KNN_3', 'Mean KNN_5', 'MSE KNN_5', 'SE KNN_5', 'Alpha KNN_5'])\n",
    "\n",
    "        for i in tqdm(range(1000)):\n",
    "            temp = del_ran(df_exog = df_noPrice, labels = df['Preis'], chance = c)\n",
    "            imputed_simul_knn.at[i] = impute_knn(temp[0], temp[1], temp[2], temp[3])\n",
    "\n",
    "        return_values = []\n",
    "        \n",
    "        for column in imputed_simul_knn.columns:\n",
    "            column_mean = np.mean(imputed_simul_knn[column].to_list())\n",
    "            return_values.append(column_mean)\n",
    "        # print(return_values)\n",
    "\n",
    "        imputed_stats_knn.loc[c] =  return_values\n",
    "    imputed_stats_knn\n",
    "\n",
    "simul_knn()\n",
    "imputed_stats_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 117.08it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 116.88it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 116.50it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 104.06it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 108.07it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 108.71it/s]\n",
      "100%|██████████| 1000/1000 [00:07<00:00, 132.29it/s]\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 150.37it/s]\n",
      "  6%|▌         | 62/1000 [00:00<00:06, 151.43it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (927,6) and (5,) not aligned: 6 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         imputed_stats_ols\u001b[38;5;241m.\u001b[39mloc[c] \u001b[38;5;241m=\u001b[39m  return_values\n\u001b[0;32m     19\u001b[0m     imputed_stats_ols\n\u001b[1;32m---> 21\u001b[0m \u001b[43msimul_ols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36msimul_ols\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[0;32m      8\u001b[0m     temp \u001b[38;5;241m=\u001b[39m del_ran(df_exog \u001b[38;5;241m=\u001b[39m df_noPrice, labels \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreis\u001b[39m\u001b[38;5;124m'\u001b[39m], chance \u001b[38;5;241m=\u001b[39m c)\n\u001b[1;32m----> 9\u001b[0m     imputed_simul_ols\u001b[38;5;241m.\u001b[39mat[i] \u001b[38;5;241m=\u001b[39m \u001b[43mimpute_ols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m return_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m imputed_simul_ols\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mimpute_ols\u001b[1;34m(test_values, test_labels, train_values, train_labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimpute_ols\u001b[39m(test_values, test_labels, train_values, train_labels):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# OLS Model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# fitting the model \u001b[39;00m\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(train_labels, sm\u001b[38;5;241m.\u001b[39madd_constant(train_values))\u001b[38;5;241m.\u001b[39mfit() \n\u001b[1;32m----> 7\u001b[0m     imputed_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mlist\u001b[39m(train_labels) \u001b[38;5;241m+\u001b[39m imputed_values), np\u001b[38;5;241m.\u001b[39mmean((imputed_values\u001b[38;5;241m-\u001b[39mtest_labels)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m), stats\u001b[38;5;241m.\u001b[39msem(\u001b[38;5;28mlist\u001b[39m(train_labels) \u001b[38;5;241m+\u001b[39m imputed_values), contains_mean(\u001b[38;5;28mlist\u001b[39m(train_labels) \u001b[38;5;241m+\u001b[39m imputed_values)]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\base\\model.py:1159\u001b[0m, in \u001b[0;36mResults.predict\u001b[1;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         exog \u001b[38;5;241m=\u001b[39m exog[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m   1157\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(exog)  \u001b[38;5;66;03m# needed in count model shape[1]\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, exog, \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   1160\u001b[0m                                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[0;32m   1163\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predict_results\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:381\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    379\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (927,6) and (5,) not aligned: 6 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "def simul_ols():\n",
    "    \n",
    "    for c in np.arange(0.1, 1, 0.1):\n",
    "        \n",
    "        imputed_simul_ols = pd.DataFrame(columns=['Mean', 'MSE OLS', 'SE OLS', 'Alpha OLS'])\n",
    "\n",
    "        for i in tqdm(range(1000)):\n",
    "            \n",
    "            temp = del_ran(df_exog = df_noPrice, labels = df['Preis'], chance = c)\n",
    "            imputed_simul_ols.at[i] = impute_ols(temp[0], temp[1], temp[2], temp[3])\n",
    "\n",
    "        return_values = []\n",
    "\n",
    "        for column in imputed_simul_ols.columns:\n",
    "            column_mean = np.mean(imputed_simul_ols[column].to_list())\n",
    "            return_values.append(column_mean)\n",
    "        # print(return_values)\n",
    "\n",
    "        imputed_stats_ols.loc[c] =  return_values\n",
    "    imputed_stats_ols\n",
    "\n",
    "simul_ols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>MSE OLS</th>\n",
       "      <th>SE OLS</th>\n",
       "      <th>Alpha OLS</th>\n",
       "      <th>Mean KNN_1</th>\n",
       "      <th>MSE KNN_1</th>\n",
       "      <th>SE KNN_1</th>\n",
       "      <th>Alpha KNN_1</th>\n",
       "      <th>Mean KNN_3</th>\n",
       "      <th>MSE KNN_3</th>\n",
       "      <th>SE KNN_3</th>\n",
       "      <th>Alpha KNN_3</th>\n",
       "      <th>Mean KNN_5</th>\n",
       "      <th>MSE KNN_5</th>\n",
       "      <th>SE KNN_5</th>\n",
       "      <th>Alpha KNN_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1333.794595</td>\n",
       "      <td>134219.669661</td>\n",
       "      <td>22.951306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1328.904121</td>\n",
       "      <td>144725.958523</td>\n",
       "      <td>23.314619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1330.512545</td>\n",
       "      <td>101799.431127</td>\n",
       "      <td>23.152998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1329.303256</td>\n",
       "      <td>101453.57621</td>\n",
       "      <td>23.130188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>1333.788285</td>\n",
       "      <td>133642.519383</td>\n",
       "      <td>22.681143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1324.53373</td>\n",
       "      <td>148937.277874</td>\n",
       "      <td>23.359979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1327.898625</td>\n",
       "      <td>102555.773564</td>\n",
       "      <td>23.040364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1325.812603</td>\n",
       "      <td>101634.175516</td>\n",
       "      <td>23.001157</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>1333.818441</td>\n",
       "      <td>133538.395443</td>\n",
       "      <td>22.391974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1320.614481</td>\n",
       "      <td>150109.559518</td>\n",
       "      <td>23.373354</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1325.34474</td>\n",
       "      <td>102773.396164</td>\n",
       "      <td>22.911847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1321.947291</td>\n",
       "      <td>102668.821334</td>\n",
       "      <td>22.830639</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>1334.045515</td>\n",
       "      <td>133891.566643</td>\n",
       "      <td>22.131181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1318.347609</td>\n",
       "      <td>150563.493549</td>\n",
       "      <td>23.365886</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1323.373148</td>\n",
       "      <td>104724.100857</td>\n",
       "      <td>22.775051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1319.336405</td>\n",
       "      <td>104091.246262</td>\n",
       "      <td>22.640742</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>1333.756282</td>\n",
       "      <td>133625.111295</td>\n",
       "      <td>21.842251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1317.057001</td>\n",
       "      <td>150984.801671</td>\n",
       "      <td>23.357222</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1320.675393</td>\n",
       "      <td>107335.591272</td>\n",
       "      <td>22.60923</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1316.602002</td>\n",
       "      <td>106478.690737</td>\n",
       "      <td>22.425439</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>1333.663536</td>\n",
       "      <td>134098.651096</td>\n",
       "      <td>21.52022</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1315.224536</td>\n",
       "      <td>153330.752355</td>\n",
       "      <td>23.265215</td>\n",
       "      <td>0.909</td>\n",
       "      <td>1318.781037</td>\n",
       "      <td>111619.441456</td>\n",
       "      <td>22.409946</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1316.443462</td>\n",
       "      <td>110837.241505</td>\n",
       "      <td>22.194793</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>1332.613179</td>\n",
       "      <td>134795.991318</td>\n",
       "      <td>21.247512</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1315.451176</td>\n",
       "      <td>157534.744797</td>\n",
       "      <td>23.16521</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1318.109198</td>\n",
       "      <td>118288.138527</td>\n",
       "      <td>22.171094</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1319.605801</td>\n",
       "      <td>118169.839346</td>\n",
       "      <td>21.946924</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>1333.920427</td>\n",
       "      <td>136085.76269</td>\n",
       "      <td>21.022214</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1316.350486</td>\n",
       "      <td>165664.521796</td>\n",
       "      <td>23.057403</td>\n",
       "      <td>0.805</td>\n",
       "      <td>1321.411444</td>\n",
       "      <td>129788.427576</td>\n",
       "      <td>21.902743</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1327.002092</td>\n",
       "      <td>131910.950046</td>\n",
       "      <td>21.495037</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1319.637508</td>\n",
       "      <td>198371.575576</td>\n",
       "      <td>22.949349</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1323.164278</td>\n",
       "      <td>163663.523037</td>\n",
       "      <td>21.115205</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1315.873256</td>\n",
       "      <td>168944.307902</td>\n",
       "      <td>19.799125</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mean        MSE OLS     SE OLS Alpha OLS   Mean KNN_1  \\\n",
       "0.1  1333.794595  134219.669661  22.951306       1.0  1328.904121   \n",
       "0.2  1333.788285  133642.519383  22.681143       1.0   1324.53373   \n",
       "0.3  1333.818441  133538.395443  22.391974       1.0  1320.614481   \n",
       "0.4  1334.045515  133891.566643  22.131181       1.0  1318.347609   \n",
       "0.5  1333.756282  133625.111295  21.842251       1.0  1317.057001   \n",
       "0.6  1333.663536  134098.651096   21.52022     0.998  1315.224536   \n",
       "0.7  1332.613179  134795.991318  21.247512     0.981  1315.451176   \n",
       "0.8  1333.920427   136085.76269  21.022214     0.918  1316.350486   \n",
       "0.9          NaN            NaN        NaN       NaN  1319.637508   \n",
       "\n",
       "         MSE KNN_1   SE KNN_1 Alpha KNN_1   Mean KNN_3      MSE KNN_3  \\\n",
       "0.1  144725.958523  23.314619         1.0  1330.512545  101799.431127   \n",
       "0.2  148937.277874  23.359979         1.0  1327.898625  102555.773564   \n",
       "0.3  150109.559518  23.373354       0.996   1325.34474  102773.396164   \n",
       "0.4  150563.493549  23.365886       0.995  1323.373148  104724.100857   \n",
       "0.5  150984.801671  23.357222       0.962  1320.675393  107335.591272   \n",
       "0.6  153330.752355  23.265215       0.909  1318.781037  111619.441456   \n",
       "0.7  157534.744797   23.16521       0.875  1318.109198  118288.138527   \n",
       "0.8  165664.521796  23.057403       0.805  1321.411444  129788.427576   \n",
       "0.9  198371.575576  22.949349       0.665  1323.164278  163663.523037   \n",
       "\n",
       "      SE KNN_3 Alpha KNN_3   Mean KNN_5      MSE KNN_5   SE KNN_5 Alpha KNN_5  \n",
       "0.1  23.152998         1.0  1329.303256   101453.57621  23.130188         1.0  \n",
       "0.2  23.040364         1.0  1325.812603  101634.175516  23.001157         1.0  \n",
       "0.3  22.911847         1.0  1321.947291  102668.821334  22.830639         1.0  \n",
       "0.4  22.775051         1.0  1319.336405  104091.246262  22.640742       0.998  \n",
       "0.5   22.60923       0.994  1316.602002  106478.690737  22.425439       0.993  \n",
       "0.6  22.409946       0.977  1316.443462  110837.241505  22.194793       0.971  \n",
       "0.7  22.171094       0.936  1319.605801  118169.839346  21.946924       0.944  \n",
       "0.8  21.902743       0.881  1327.002092  131910.950046  21.495037       0.902  \n",
       "0.9  21.115205       0.691  1315.873256  168944.307902  19.799125       0.599  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([imputed_stats_ols, imputed_stats_knn], axis=1).to_csv('MCAR_Simulation_Top5 (neu)')\n",
    "pd.concat([imputed_stats_ols, imputed_stats_knn], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
