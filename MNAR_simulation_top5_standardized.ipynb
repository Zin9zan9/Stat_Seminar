{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung von DataFrames und Data Cleaning\n",
    "df = pd.read_csv('Laptop-Preise.csv', sep=';', decimal=',')\n",
    "df = df[df.extern_Schnittstellen != 2300] # Ausreißer löschen\n",
    "df = df.reset_index(drop=True) # Reset Index\n",
    "\n",
    "# Nur die 5 Spalten auswählen, die auch den größten Erklärungsgehalt haben\n",
    "selected_columns = ['Preis', 'Akku_Kapazitaet', 'Arbeitsspeicher', 'Kerne', 'Mobilfunk_vorhanden', 'SSD']\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "df_noPrice = df.drop('Preis', axis=1)\n",
    "imputed_simul_knn = pd.DataFrame(columns=['MSE KNN_1', 'MSE KNN_3', 'MSE KNN_5', 'SE KNN_1', 'SE KNN_3', 'SE KNN_5'])\n",
    "imputed_stats_knn = pd.DataFrame(columns=['MSE KNN_1', 'MSE KNN_3', 'MSE KNN_5', 'SE KNN_1', 'SE KNN_3', 'SE KNN_5'], index = np.arange(0.1, 1, 0.1))\n",
    "\n",
    "imputed_simul_ols = pd.DataFrame(columns=['MSE OLS', 'SE OLS'])\n",
    "imputed_stats_ols = pd.DataFrame(columns=['MSE OLS', 'SE OLS'], index = np.arange(0.1, 1, 0.1))\n",
    "\n",
    "# Skalierung (Standardisierung) von df_noPrice\n",
    "col_names = df_noPrice.columns\n",
    "scaler = StandardScaler().fit(df_noPrice.values)\n",
    "df_noPrice = scaler.transform(df_noPrice.values)\n",
    "df_noPrice = pd.DataFrame(df_noPrice, columns=col_names)\n",
    "\n",
    "# Skalierung (Standardisierung) von df mit Preis (Preis ist unverändert)\n",
    "df_std = df_noPrice.copy()\n",
    "df_std.insert(0, 'Preis', df['Preis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Preis   R-squared:                       0.789\n",
      "Model:                            OLS   Adj. R-squared:                  0.788\n",
      "Method:                 Least Squares   F-statistic:                     771.4\n",
      "Date:                Sat, 13 Jan 2024   Prob (F-statistic):               0.00\n",
      "Time:                        19:02:28   Log-Likelihood:                -7534.6\n",
      "No. Observations:                1038   AIC:                         1.508e+04\n",
      "Df Residuals:                    1032   BIC:                         1.511e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                1333.9633     10.699    124.677      0.000    1312.968    1354.958\n",
      "Akku_Kapazitaet       301.3112     14.713     20.479      0.000     272.440     330.182\n",
      "Arbeitsspeicher       271.7724     15.320     17.740      0.000     241.711     301.834\n",
      "Kerne                  86.4238     15.334      5.636      0.000      56.335     116.513\n",
      "Mobilfunk_vorhanden   131.1533     10.885     12.049      0.000     109.794     152.512\n",
      "SSD                   138.2031     13.472     10.259      0.000     111.768     164.639\n",
      "==============================================================================\n",
      "Omnibus:                       47.112   Durbin-Watson:                   1.681\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.133\n",
      "Skew:                           0.486   Prob(JB):                     1.07e-12\n",
      "Kurtosis:                       3.573   Cond. No.                         2.84\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# OLS Model \n",
    "# fitting the model \n",
    "# df_noPrice ist bereits standardisiert\n",
    "model = sm.OLS(df['Preis'], sm.add_constant(df_noPrice)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, test_values, train_labels, test_labels = train_test_split(df_noPrice, df['Preis'], test_size=0.01)\n",
    "\n",
    "def del_ran(df_exog, labels, chance):\n",
    "    rand_array = np.random.rand(df_exog.shape[0])\n",
    "    delete_entries = rand_array < chance\n",
    "    keep_entries = rand_array >= chance\n",
    "    \n",
    "    return [df_exog[delete_entries], labels[delete_entries], df_exog[keep_entries], labels[keep_entries]]\n",
    "\n",
    "temp = del_ran(df_exog = df_noPrice, labels = df['Preis'], chance = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_ols(test_values, test_labels, train_values, train_labels):\n",
    "    \n",
    "    # OLS Model\n",
    "    # fitting the model \n",
    "    model = sm.OLS(train_labels, sm.add_constant(train_values)).fit() \n",
    "\n",
    "    imputed_values = model.predict(exog = sm.add_constant(test_values, has_constant='add')).tolist()\n",
    "    return [np.mean((imputed_values-test_labels)**2), stats.sem(list(train_labels) + imputed_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_knn(test_values, test_labels, train_values, train_labels):\n",
    "    \n",
    "    tree = KDTree(train_values.values, leaf_size=5)\n",
    "\n",
    "    imputed_values_knn_1 = []\n",
    "    imputed_values_knn_3 = []\n",
    "    imputed_values_knn_5 = []\n",
    "\n",
    "    for index, entry in enumerate(test_values.values):\n",
    " \n",
    "        dist, ind = tree.query([entry], k=5)\n",
    "        ind = ind[0]\n",
    "\n",
    "        current_impute_knn_1 = np.mean(train_labels.values[ind][0])\n",
    "        current_impute_knn_3 = np.mean(train_labels.values[ind][:3])\n",
    "        current_impute_knn_5 = np.mean(train_labels.values[ind])\n",
    "\n",
    "        imputed_values_knn_1.append(current_impute_knn_1)\n",
    "        imputed_values_knn_3.append(current_impute_knn_3)\n",
    "        imputed_values_knn_5.append(current_impute_knn_5)\n",
    "       \n",
    "        # print(train_labels.values[ind])\n",
    "        # print(current_impute_knn_1//1, current_impute_knn_3//1, current_impute_knn_5//1)\n",
    "        # print(test_labels.values[index])\n",
    "        # print(train_values.values[ind])\n",
    "\n",
    "    mse_knn_1 = np.mean((test_labels.values - imputed_values_knn_1)**2)\n",
    "    mse_knn_3 = np.mean((test_labels.values - imputed_values_knn_3)**2)\n",
    "    mse_knn_5 = np.mean((test_labels.values - imputed_values_knn_5)**2)\n",
    "\n",
    "    sem_knn_1 = stats.sem(list(train_labels.values)+imputed_values_knn_1)\n",
    "    sem_knn_3 = stats.sem(list(train_labels.values)+imputed_values_knn_3)\n",
    "    sem_knn_5 = stats.sem(list(train_labels.values)+imputed_values_knn_5)\n",
    "\n",
    "\n",
    "    return [mse_knn_1, mse_knn_3, mse_knn_5, sem_knn_1, sem_knn_3, sem_knn_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:13<00:00, 75.10it/s]\n",
      "100%|██████████| 1000/1000 [00:22<00:00, 43.76it/s]\n",
      "100%|██████████| 1000/1000 [00:33<00:00, 29.78it/s]\n",
      "100%|██████████| 1000/1000 [00:45<00:00, 21.91it/s]\n",
      "100%|██████████| 1000/1000 [00:56<00:00, 17.64it/s]\n",
      "100%|██████████| 1000/1000 [01:04<00:00, 15.57it/s]\n",
      "100%|██████████| 1000/1000 [01:15<00:00, 13.24it/s]\n",
      "100%|██████████| 1000/1000 [01:25<00:00, 11.74it/s]\n",
      "100%|██████████| 1000/1000 [01:36<00:00, 10.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def simul_knn():\n",
    "    for c in np.arange(0.1, 1, 0.1):\n",
    "\n",
    "        for i in tqdm(range(1000)):\n",
    "            temp = del_ran(df_exog = df_noPrice, labels = df['Preis'], chance = c)\n",
    "            imputed_simul_knn.at[i] = impute_knn(temp[0], temp[1], temp[2], temp[3])\n",
    "\n",
    "        imputed_stats_knn.loc[c] = imputed_simul_knn.mean()\n",
    "    imputed_stats_knn\n",
    "\n",
    "simul_knn()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 149.49it/s]\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 164.06it/s]\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 147.84it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 181.96it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 168.52it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 178.85it/s]\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 150.08it/s]\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 161.39it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 172.61it/s]\n"
     ]
    }
   ],
   "source": [
    "def simul_ols():\n",
    "    for c in np.arange(0.1, 1, 0.1):\n",
    "\n",
    "        for i in tqdm(range(1000)):\n",
    "            temp = del_ran(df_exog = df_noPrice, labels = df['Preis'], chance = c)\n",
    "            imputed_simul_ols.at[i] = impute_ols(temp[0], temp[1], temp[2], temp[3])\n",
    "        imputed_stats_ols.loc[c] = imputed_simul_ols.mean()\n",
    "    imputed_stats_ols\n",
    "\n",
    "simul_ols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Simulation wird irgendwann ein Fehler geworfen. Das liegt daran, dass, wenn zu viele Einträge gelöscht werden, die Matrix ihren vollen Rang verliert. Einige Dummy-Variablen sind relativ selten. Wenn nun alle Einträge mit der Dummy-Variable auf 1 (oder 0) gelöscht werden, dann wird wegen der linearen Abhängigkeit zur Konstante diese Variable gelöscht - so vermeiden wir Kollinarität.\n",
    "Wenn dann aber nun im Test-Datensatz die Variable in ihrer Ausprägung 0 (oder 1) besitzt, dann können haben wir dafür keinen passenden Regressionskoeffizienten. Es werden dann 33 Variablen als Input geliefert, obwohl wir nur 32 Regressionskoeffizienten haben. Anschließend wird eine Fehlermeldung geworfen, dass der Eintrag, den wir vorhersagen wollen die falsche shape hat (32 statt 33). \n",
    "Es stellt sich zudem an diesem Punkt außerdem die Frage, wie sinnvoll es ist Variablen imputieren zu wollen, bei denen 70% der Einträge fehlen.\n",
    "\n",
    "Bei den Auswertungen ist zu beachten, dass der wahre Standardfehler von Preis bei 23.2318 liegt.\n",
    "Wir können also deutlich erkennen, dass jede Imputation der fehlenden Werte den Standardfehler künstlich verringert.\n",
    "\n",
    "Es ist auch relativ deutlich klar, dass ein höherer k-Wert für KNN dazu führt, dass der Standardfehler weiter sinkt. Das liegt daran, dass bei einem höheren k-Wert der Mittelwert von einem größeren Teil des Datensatzes genommen wird. Dadurch wird der Mittelwert (oder zumindest Mittelwert-nahe Werte) imputiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE OLS</th>\n",
       "      <th>SE OLS</th>\n",
       "      <th>MSE KNN_1</th>\n",
       "      <th>MSE KNN_3</th>\n",
       "      <th>MSE KNN_5</th>\n",
       "      <th>SE KNN_1</th>\n",
       "      <th>SE KNN_3</th>\n",
       "      <th>SE KNN_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>119245.735104</td>\n",
       "      <td>22.984699</td>\n",
       "      <td>116770.142579</td>\n",
       "      <td>95203.44479</td>\n",
       "      <td>94921.032905</td>\n",
       "      <td>23.32205</td>\n",
       "      <td>23.214856</td>\n",
       "      <td>23.19374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>120033.382944</td>\n",
       "      <td>22.730275</td>\n",
       "      <td>124249.139637</td>\n",
       "      <td>98554.959703</td>\n",
       "      <td>97555.710257</td>\n",
       "      <td>23.434547</td>\n",
       "      <td>23.178803</td>\n",
       "      <td>23.121627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>120302.551646</td>\n",
       "      <td>22.491758</td>\n",
       "      <td>128478.170649</td>\n",
       "      <td>100163.602806</td>\n",
       "      <td>98160.465573</td>\n",
       "      <td>23.517282</td>\n",
       "      <td>23.099106</td>\n",
       "      <td>22.989855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>120688.517929</td>\n",
       "      <td>22.24438</td>\n",
       "      <td>131191.476558</td>\n",
       "      <td>102606.077241</td>\n",
       "      <td>100290.433118</td>\n",
       "      <td>23.559607</td>\n",
       "      <td>22.989658</td>\n",
       "      <td>22.819185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>120977.103493</td>\n",
       "      <td>22.009073</td>\n",
       "      <td>135937.099852</td>\n",
       "      <td>106143.580781</td>\n",
       "      <td>103855.640808</td>\n",
       "      <td>23.598222</td>\n",
       "      <td>22.847831</td>\n",
       "      <td>22.62551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>121639.69477</td>\n",
       "      <td>21.715219</td>\n",
       "      <td>141867.097612</td>\n",
       "      <td>110421.655814</td>\n",
       "      <td>108926.183917</td>\n",
       "      <td>23.559771</td>\n",
       "      <td>22.606785</td>\n",
       "      <td>22.316978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>121952.115228</td>\n",
       "      <td>21.485907</td>\n",
       "      <td>150205.020485</td>\n",
       "      <td>117145.480998</td>\n",
       "      <td>116295.654131</td>\n",
       "      <td>23.500937</td>\n",
       "      <td>22.312434</td>\n",
       "      <td>21.97279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>123486.915217</td>\n",
       "      <td>21.220231</td>\n",
       "      <td>164057.651964</td>\n",
       "      <td>128669.002791</td>\n",
       "      <td>127585.690546</td>\n",
       "      <td>23.30574</td>\n",
       "      <td>21.903111</td>\n",
       "      <td>21.418192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>129019.769876</td>\n",
       "      <td>21.049056</td>\n",
       "      <td>193353.307628</td>\n",
       "      <td>152856.653519</td>\n",
       "      <td>153180.733529</td>\n",
       "      <td>22.985484</td>\n",
       "      <td>20.997723</td>\n",
       "      <td>19.923487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MSE OLS     SE OLS      MSE KNN_1      MSE KNN_3      MSE KNN_5  \\\n",
       "0.1  119245.735104  22.984699  116770.142579    95203.44479   94921.032905   \n",
       "0.2  120033.382944  22.730275  124249.139637   98554.959703   97555.710257   \n",
       "0.3  120302.551646  22.491758  128478.170649  100163.602806   98160.465573   \n",
       "0.4  120688.517929   22.24438  131191.476558  102606.077241  100290.433118   \n",
       "0.5  120977.103493  22.009073  135937.099852  106143.580781  103855.640808   \n",
       "0.6   121639.69477  21.715219  141867.097612  110421.655814  108926.183917   \n",
       "0.7  121952.115228  21.485907  150205.020485  117145.480998  116295.654131   \n",
       "0.8  123486.915217  21.220231  164057.651964  128669.002791  127585.690546   \n",
       "0.9  129019.769876  21.049056  193353.307628  152856.653519  153180.733529   \n",
       "\n",
       "      SE KNN_1   SE KNN_3   SE KNN_5  \n",
       "0.1   23.32205  23.214856   23.19374  \n",
       "0.2  23.434547  23.178803  23.121627  \n",
       "0.3  23.517282  23.099106  22.989855  \n",
       "0.4  23.559607  22.989658  22.819185  \n",
       "0.5  23.598222  22.847831   22.62551  \n",
       "0.6  23.559771  22.606785  22.316978  \n",
       "0.7  23.500937  22.312434   21.97279  \n",
       "0.8   23.30574  21.903111  21.418192  \n",
       "0.9  22.985484  20.997723  19.923487  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([imputed_stats_ols, imputed_stats_knn], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
